{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tribal-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the directory to sys.path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# Now you can import the module\n",
    "from utils.tle_processing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacetrack.operators as op\n",
    "from datetime import datetime,timedelta\n",
    "import pandas as pd\n",
    "from spacetrack import SpaceTrackClient\n",
    "from io import StringIO  # Import StringIO\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decent-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exotic-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-station",
   "metadata": {},
   "source": [
    "# Classical ML Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "critical-bones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Derivative Mean Motion</th>\n",
       "      <th>Inclination (degrees)</th>\n",
       "      <th>Right Ascension of the Ascending Node (degrees)</th>\n",
       "      <th>Argument of Perigee (degrees)</th>\n",
       "      <th>Mean Anomaly (degrees)</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Mean Motion (revolutions per day)</th>\n",
       "      <th>Revolution Number at Epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>51.644800</td>\n",
       "      <td>77.042350</td>\n",
       "      <td>208.400550</td>\n",
       "      <td>320.463100</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>15.497978</td>\n",
       "      <td>37584.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>51.644567</td>\n",
       "      <td>74.151133</td>\n",
       "      <td>211.103567</td>\n",
       "      <td>277.293067</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>15.498221</td>\n",
       "      <td>37593.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>51.644680</td>\n",
       "      <td>69.554840</td>\n",
       "      <td>215.693640</td>\n",
       "      <td>221.644740</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>15.498584</td>\n",
       "      <td>37608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>51.644860</td>\n",
       "      <td>64.713420</td>\n",
       "      <td>219.864140</td>\n",
       "      <td>202.583880</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>15.498874</td>\n",
       "      <td>37623.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>51.644740</td>\n",
       "      <td>59.072260</td>\n",
       "      <td>225.670000</td>\n",
       "      <td>219.529780</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>15.499123</td>\n",
       "      <td>37640.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            First Derivative Mean Motion  Inclination (degrees)  \\\n",
       "Epoch                                                             \n",
       "2022-12-31                      0.000157              51.644800   \n",
       "2023-01-01                      0.000166              51.644567   \n",
       "2023-01-02                      0.000175              51.644680   \n",
       "2023-01-03                      0.000162              51.644860   \n",
       "2023-01-04                      0.000142              51.644740   \n",
       "\n",
       "            Right Ascension of the Ascending Node (degrees)  \\\n",
       "Epoch                                                         \n",
       "2022-12-31                                        77.042350   \n",
       "2023-01-01                                        74.151133   \n",
       "2023-01-02                                        69.554840   \n",
       "2023-01-03                                        64.713420   \n",
       "2023-01-04                                        59.072260   \n",
       "\n",
       "            Argument of Perigee (degrees)  Mean Anomaly (degrees)  \\\n",
       "Epoch                                                               \n",
       "2022-12-31                     208.400550              320.463100   \n",
       "2023-01-01                     211.103567              277.293067   \n",
       "2023-01-02                     215.693640              221.644740   \n",
       "2023-01-03                     219.864140              202.583880   \n",
       "2023-01-04                     225.670000              219.529780   \n",
       "\n",
       "            Eccentricity  Mean Motion (revolutions per day)  \\\n",
       "Epoch                                                         \n",
       "2022-12-31      0.000525                          15.497978   \n",
       "2023-01-01      0.000519                          15.498221   \n",
       "2023-01-02      0.000511                          15.498584   \n",
       "2023-01-03      0.000499                          15.498874   \n",
       "2023-01-04      0.000497                          15.499123   \n",
       "\n",
       "            Revolution Number at Epoch  \n",
       "Epoch                                   \n",
       "2022-12-31                37584.500000  \n",
       "2023-01-01                37593.666667  \n",
       "2023-01-02                37608.000000  \n",
       "2023-01-03                37623.200000  \n",
       "2023-01-04                37640.800000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_tle_df = pd.read_csv('sample_dataset/sample_daily_records_data.csv')\n",
    "resample_tle_df.set_index('Epoch', inplace=True)\n",
    "resample_tle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "steady-carpet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['First Derivative Mean Motion', 'Inclination (degrees)',\n",
       "       'Right Ascension of the Ascending Node (degrees)',\n",
       "       'Argument of Perigee (degrees)', 'Mean Anomaly (degrees)',\n",
       "       'Eccentricity', 'Mean Motion (revolutions per day)',\n",
       "       'Revolution Number at Epoch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_tle_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-shadow",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dimensional-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Prepare Sample Data ---\n",
    "data_for_training = resample_tle_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-prisoner",
   "metadata": {},
   "source": [
    "## First differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "moderate-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_for_training['Revolution Number at Epoch_Diff'] =  data_for_training['Revolution Number at Epoch'].diff()\n",
    "\n",
    "# data_for_training.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-hudson",
   "metadata": {},
   "source": [
    "## Cyclical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "short-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical_feature(df: pd.DataFrame, column_name: str, period: float = 360.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encodes a cyclical feature (like degrees, hours, or months) using\n",
    "    sine and cosine projection.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the cyclical feature column (in degrees).\n",
    "        period (float): The length of the cycle (e.g., 360 for degrees, 24 for hours).\n",
    "                        Defaults to 360.0.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with two added columns:\n",
    "                      <column_name>_sin and <column_name>_cos.\n",
    "    \"\"\"\n",
    "    print(f\"--- Encoding '{column_name}' with period {period} ---\")\n",
    "\n",
    "    # 1. Conversion to Radians: Necessary for NumPy's sin/cos functions.\n",
    "    # The formula converts the value into a proportion of the cycle (0 to 2*pi).\n",
    "    angle_rad = 2 * np.pi * df[column_name] / period\n",
    "\n",
    "    # 2. Sine and Cosine Projection\n",
    "    sin_col = f'{column_name}_sin'\n",
    "    cos_col = f'{column_name}_cos'\n",
    "\n",
    "    df[sin_col] = np.sin(angle_rad)\n",
    "    df[cos_col] = np.cos(angle_rad)\n",
    "\n",
    "    # Optional: Drop the original column if you don't need it.\n",
    "    # df = df.drop(columns=[column_name])\n",
    "\n",
    "    print(f\"Created columns: '{sin_col}' and '{cos_col}'\")\n",
    "    return df\n",
    "\n",
    "def decode_cyclical_feature(df: pd.DataFrame, sin_col: str, cos_col: str, period: float = 360.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reconstructs the original cyclical feature value (in degrees) from its\n",
    "    sine and cosine components.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing sine and cosine components.\n",
    "        sin_col (str): The name of the sine component column.\n",
    "        cos_col (str): The name of the cosine component column.\n",
    "        period (float): The length of the cycle (e.g., 360 for degrees, 24 for hours).\n",
    "                        Defaults to 360.0.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new reconstructed column.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Decoding from '{sin_col}' and '{cos_col}' ---\")\n",
    "    reconstructed_col = f'{sin_col.split(\"_sin\")[0]}_reconstructed'\n",
    "\n",
    "    # 1. Use arctan2 to get the angle in radians (range: [-pi, pi]).\n",
    "    # arctan2 is crucial as it correctly handles all four quadrants.\n",
    "    angle_rad = np.arctan2(df[sin_col], df[cos_col])\n",
    "\n",
    "    # 2. Scale back to the original period (e.g., [0, 360]).\n",
    "    # Formula: (angle_rad / (2 * pi)) * period\n",
    "    angle_normalized = angle_rad * (period / (2 * np.pi))\n",
    "\n",
    "    # 3. Handle the cyclical nature to ensure the result is non-negative (e.g., [0, 360)).\n",
    "    # The decoded value might be negative (e.g., -90 degrees). We shift it to the\n",
    "    # equivalent positive value (e.g., 270 degrees).\n",
    "    df[reconstructed_col] = np.where(angle_normalized < 0,\n",
    "                                     angle_normalized + period,\n",
    "                                     angle_normalized)\n",
    "\n",
    "    print(f\"Reconstructed column: '{reconstructed_col}'\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "surprised-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical_feature(df: pd.DataFrame, column_name: str, period: float = 360.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encodes a cyclical feature (like degrees, hours, or months) using\n",
    "    sine and cosine projection.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the cyclical feature column (in degrees).\n",
    "        period (float): The length of the cycle (e.g., 360 for degrees, 24 for hours).\n",
    "                        Defaults to 360.0.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with two added columns:\n",
    "                      <column_name>_sin and <column_name>_cos.\n",
    "    \"\"\"\n",
    "    print(f\"--- Encoding '{column_name}' with period {period} ---\")\n",
    "\n",
    "    # 1. Conversion to Radians: Necessary for NumPy's sin/cos functions.\n",
    "    # The formula converts the value into a proportion of the cycle (0 to 2*pi).\n",
    "    angle_rad = 2 * np.pi * df[column_name] / period\n",
    "\n",
    "    # 2. Sine and Cosine Projection\n",
    "    sin_col = f'{column_name}_sin'\n",
    "    cos_col = f'{column_name}_cos'\n",
    "\n",
    "    df[sin_col] = np.sin(angle_rad)\n",
    "    df[cos_col] = np.cos(angle_rad)\n",
    "\n",
    "    # Optional: Drop the original column if you don't need it.\n",
    "    # df = df.drop(columns=[column_name])\n",
    "\n",
    "    print(f\"Created columns: '{sin_col}' and '{cos_col}'\")\n",
    "    return df\n",
    "\n",
    "def decode_cyclical_feature(df: pd.DataFrame, sin_col: str, cos_col: str, period: float = 360.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reconstructs the original cyclical feature value (in degrees) from its\n",
    "    sine and cosine components.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing sine and cosine components.\n",
    "        sin_col (str): The name of the sine component column.\n",
    "        cos_col (str): The name of the cosine component column.\n",
    "        period (float): The length of the cycle (e.g., 360 for degrees, 24 for hours).\n",
    "                        Defaults to 360.0.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new reconstructed column.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Decoding from '{sin_col}' and '{cos_col}' ---\")\n",
    "    reconstructed_col = f'{sin_col.split(\"_sin\")[0]}_reconstructed'\n",
    "\n",
    "    # 1. Use arctan2 to get the angle in radians (range: [-pi, pi]).\n",
    "    # arctan2 is crucial as it correctly handles all four quadrants.\n",
    "    angle_rad = np.arctan2(df[sin_col], df[cos_col])\n",
    "\n",
    "    # 2. Scale back to the original period (e.g., [0, 360]).\n",
    "    # Formula: (angle_rad / (2 * pi)) * period\n",
    "    angle_normalized = angle_rad * (period / (2 * np.pi))\n",
    "\n",
    "    # 3. Handle the cyclical nature to ensure the result is non-negative (e.g., [0, 360)).\n",
    "    # The decoded value might be negative (e.g., -90 degrees). We shift it to the\n",
    "    # equivalent positive value (e.g., 270 degrees).\n",
    "    df[reconstructed_col] = np.where(angle_normalized < 0,\n",
    "                                     angle_normalized + period,\n",
    "                                     angle_normalized)\n",
    "\n",
    "    print(f\"Reconstructed column: '{reconstructed_col}'\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "located-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Encoding 'Right Ascension of the Ascending Node (degrees)' with period 360.0 ---\n",
      "Created columns: 'Right Ascension of the Ascending Node (degrees)_sin' and 'Right Ascension of the Ascending Node (degrees)_cos'\n",
      "--- Encoding 'Argument of Perigee (degrees)' with period 360.0 ---\n",
      "Created columns: 'Argument of Perigee (degrees)_sin' and 'Argument of Perigee (degrees)_cos'\n",
      "--- Encoding 'Mean Anomaly (degrees)' with period 360.0 ---\n",
      "Created columns: 'Mean Anomaly (degrees)_sin' and 'Mean Anomaly (degrees)_cos'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Derivative Mean Motion</th>\n",
       "      <th>Inclination (degrees)</th>\n",
       "      <th>Right Ascension of the Ascending Node (degrees)</th>\n",
       "      <th>Argument of Perigee (degrees)</th>\n",
       "      <th>Mean Anomaly (degrees)</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Mean Motion (revolutions per day)</th>\n",
       "      <th>Revolution Number at Epoch</th>\n",
       "      <th>Revolution Number at Epoch_Diff</th>\n",
       "      <th>Right Ascension of the Ascending Node (degrees)_sin</th>\n",
       "      <th>Right Ascension of the Ascending Node (degrees)_cos</th>\n",
       "      <th>Argument of Perigee (degrees)_sin</th>\n",
       "      <th>Argument of Perigee (degrees)_cos</th>\n",
       "      <th>Mean Anomaly (degrees)_sin</th>\n",
       "      <th>Mean Anomaly (degrees)_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>51.644567</td>\n",
       "      <td>74.151133</td>\n",
       "      <td>211.103567</td>\n",
       "      <td>277.293067</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>15.498221</td>\n",
       "      <td>37593.666667</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>0.273101</td>\n",
       "      <td>-0.516587</td>\n",
       "      <td>-0.856235</td>\n",
       "      <td>-0.991910</td>\n",
       "      <td>0.126945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>51.644680</td>\n",
       "      <td>69.554840</td>\n",
       "      <td>215.693640</td>\n",
       "      <td>221.644740</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>15.498584</td>\n",
       "      <td>37608.000000</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>0.937007</td>\n",
       "      <td>0.349311</td>\n",
       "      <td>-0.583451</td>\n",
       "      <td>-0.812148</td>\n",
       "      <td>-0.664510</td>\n",
       "      <td>-0.747279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>51.644860</td>\n",
       "      <td>64.713420</td>\n",
       "      <td>219.864140</td>\n",
       "      <td>202.583880</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>15.498874</td>\n",
       "      <td>37623.200000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0.904183</td>\n",
       "      <td>0.427146</td>\n",
       "      <td>-0.640969</td>\n",
       "      <td>-0.767566</td>\n",
       "      <td>-0.384036</td>\n",
       "      <td>-0.923318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>51.644740</td>\n",
       "      <td>59.072260</td>\n",
       "      <td>225.670000</td>\n",
       "      <td>219.529780</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>15.499123</td>\n",
       "      <td>37640.800000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>0.857816</td>\n",
       "      <td>0.513957</td>\n",
       "      <td>-0.715327</td>\n",
       "      <td>-0.698790</td>\n",
       "      <td>-0.636479</td>\n",
       "      <td>-0.771294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0.000139</td>\n",
       "      <td>51.644820</td>\n",
       "      <td>54.697760</td>\n",
       "      <td>228.970120</td>\n",
       "      <td>250.770840</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>15.499368</td>\n",
       "      <td>37654.600000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.577890</td>\n",
       "      <td>-0.754367</td>\n",
       "      <td>-0.656453</td>\n",
       "      <td>-0.944209</td>\n",
       "      <td>-0.329347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            First Derivative Mean Motion  Inclination (degrees)  \\\n",
       "Epoch                                                             \n",
       "2023-01-01                      0.000166              51.644567   \n",
       "2023-01-02                      0.000175              51.644680   \n",
       "2023-01-03                      0.000162              51.644860   \n",
       "2023-01-04                      0.000142              51.644740   \n",
       "2023-01-05                      0.000139              51.644820   \n",
       "\n",
       "            Right Ascension of the Ascending Node (degrees)  \\\n",
       "Epoch                                                         \n",
       "2023-01-01                                        74.151133   \n",
       "2023-01-02                                        69.554840   \n",
       "2023-01-03                                        64.713420   \n",
       "2023-01-04                                        59.072260   \n",
       "2023-01-05                                        54.697760   \n",
       "\n",
       "            Argument of Perigee (degrees)  Mean Anomaly (degrees)  \\\n",
       "Epoch                                                               \n",
       "2023-01-01                     211.103567              277.293067   \n",
       "2023-01-02                     215.693640              221.644740   \n",
       "2023-01-03                     219.864140              202.583880   \n",
       "2023-01-04                     225.670000              219.529780   \n",
       "2023-01-05                     228.970120              250.770840   \n",
       "\n",
       "            Eccentricity  Mean Motion (revolutions per day)  \\\n",
       "Epoch                                                         \n",
       "2023-01-01      0.000519                          15.498221   \n",
       "2023-01-02      0.000511                          15.498584   \n",
       "2023-01-03      0.000499                          15.498874   \n",
       "2023-01-04      0.000497                          15.499123   \n",
       "2023-01-05      0.000490                          15.499368   \n",
       "\n",
       "            Revolution Number at Epoch  Revolution Number at Epoch_Diff  \\\n",
       "Epoch                                                                     \n",
       "2023-01-01                37593.666667                         9.166667   \n",
       "2023-01-02                37608.000000                        14.333333   \n",
       "2023-01-03                37623.200000                        15.200000   \n",
       "2023-01-04                37640.800000                        17.600000   \n",
       "2023-01-05                37654.600000                        13.800000   \n",
       "\n",
       "            Right Ascension of the Ascending Node (degrees)_sin  \\\n",
       "Epoch                                                             \n",
       "2023-01-01                                           0.961985     \n",
       "2023-01-02                                           0.937007     \n",
       "2023-01-03                                           0.904183     \n",
       "2023-01-04                                           0.857816     \n",
       "2023-01-05                                           0.816115     \n",
       "\n",
       "            Right Ascension of the Ascending Node (degrees)_cos  \\\n",
       "Epoch                                                             \n",
       "2023-01-01                                           0.273101     \n",
       "2023-01-02                                           0.349311     \n",
       "2023-01-03                                           0.427146     \n",
       "2023-01-04                                           0.513957     \n",
       "2023-01-05                                           0.577890     \n",
       "\n",
       "            Argument of Perigee (degrees)_sin  \\\n",
       "Epoch                                           \n",
       "2023-01-01                          -0.516587   \n",
       "2023-01-02                          -0.583451   \n",
       "2023-01-03                          -0.640969   \n",
       "2023-01-04                          -0.715327   \n",
       "2023-01-05                          -0.754367   \n",
       "\n",
       "            Argument of Perigee (degrees)_cos  Mean Anomaly (degrees)_sin  \\\n",
       "Epoch                                                                       \n",
       "2023-01-01                          -0.856235                   -0.991910   \n",
       "2023-01-02                          -0.812148                   -0.664510   \n",
       "2023-01-03                          -0.767566                   -0.384036   \n",
       "2023-01-04                          -0.698790                   -0.636479   \n",
       "2023-01-05                          -0.656453                   -0.944209   \n",
       "\n",
       "            Mean Anomaly (degrees)_cos  \n",
       "Epoch                                   \n",
       "2023-01-01                    0.126945  \n",
       "2023-01-02                   -0.747279  \n",
       "2023-01-03                   -0.923318  \n",
       "2023-01-04                   -0.771294  \n",
       "2023-01-05                   -0.329347  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['Right Ascension of the Ascending Node (degrees)','Argument of Perigee (degrees)', 'Mean Anomaly (degrees)']\n",
    "CYCLE_PERIOD = 360.0\n",
    "FEATURE_COL = 'Right Ascension of the Ascending Node (degrees)'\n",
    "data_for_training = encode_cyclical_feature(data_for_training, FEATURE_COL, CYCLE_PERIOD)\n",
    "\n",
    "FEATURE_COL = 'Argument of Perigee (degrees)'\n",
    "data_for_training = encode_cyclical_feature(data_for_training, FEATURE_COL, CYCLE_PERIOD)\n",
    "\n",
    "FEATURE_COL = 'Mean Anomaly (degrees)'\n",
    "data_for_training = encode_cyclical_feature(data_for_training, FEATURE_COL, CYCLE_PERIOD)\n",
    "\n",
    "\n",
    "data_for_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "accompanied-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-frame",
   "metadata": {},
   "source": [
    "# Column selection for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "metric-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_features = ['First Derivative Mean Motion', 'Inclination (degrees)',\n",
    "       'Right Ascension of the Ascending Node (degrees)',\n",
    "       'Argument of Perigee (degrees)', 'Mean Anomaly (degrees)',\n",
    "       'Eccentricity', 'Mean Motion (revolutions per day)',\n",
    "       'Revolution Number at Epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vertical-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = ['First Derivative Mean Motion', 'Inclination (degrees)','Eccentricity','Mean Motion (revolutions per day)']\n",
    "\n",
    "diff_features = ['Revolution Number at Epoch_Diff']\n",
    "\n",
    "cyclical_features = ['Right Ascension of the Ascending Node (degrees)_sin',\n",
    "        'Right Ascension of the Ascending Node (degrees)_cos',\n",
    "        'Argument of Perigee (degrees)_sin',\n",
    "        'Argument of Perigee (degrees)_cos', \n",
    "        'Mean Anomaly (degrees)_sin',\n",
    "        'Mean Anomaly (degrees)_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "expected-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = original_features+diff_features+cyclical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-press",
   "metadata": {},
   "source": [
    "# Generating lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pending-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Derivative Mean Motion</th>\n",
       "      <th>Inclination (degrees)</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Mean Motion (revolutions per day)</th>\n",
       "      <th>Revolution Number at Epoch_Diff</th>\n",
       "      <th>Right Ascension of the Ascending Node (degrees)_sin</th>\n",
       "      <th>Right Ascension of the Ascending Node (degrees)_cos</th>\n",
       "      <th>Argument of Perigee (degrees)_sin</th>\n",
       "      <th>Argument of Perigee (degrees)_cos</th>\n",
       "      <th>Mean Anomaly (degrees)_sin</th>\n",
       "      <th>Mean Anomaly (degrees)_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>51.644567</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>15.498221</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>0.273101</td>\n",
       "      <td>-0.516587</td>\n",
       "      <td>-0.856235</td>\n",
       "      <td>-0.991910</td>\n",
       "      <td>0.126945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>51.644680</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>15.498584</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>0.937007</td>\n",
       "      <td>0.349311</td>\n",
       "      <td>-0.583451</td>\n",
       "      <td>-0.812148</td>\n",
       "      <td>-0.664510</td>\n",
       "      <td>-0.747279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>51.644860</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>15.498874</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0.904183</td>\n",
       "      <td>0.427146</td>\n",
       "      <td>-0.640969</td>\n",
       "      <td>-0.767566</td>\n",
       "      <td>-0.384036</td>\n",
       "      <td>-0.923318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>51.644740</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>15.499123</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>0.857816</td>\n",
       "      <td>0.513957</td>\n",
       "      <td>-0.715327</td>\n",
       "      <td>-0.698790</td>\n",
       "      <td>-0.636479</td>\n",
       "      <td>-0.771294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0.000139</td>\n",
       "      <td>51.644820</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>15.499368</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.577890</td>\n",
       "      <td>-0.754367</td>\n",
       "      <td>-0.656453</td>\n",
       "      <td>-0.944209</td>\n",
       "      <td>-0.329347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            First Derivative Mean Motion  Inclination (degrees)  Eccentricity  \\\n",
       "Epoch                                                                           \n",
       "2023-01-01                      0.000166              51.644567      0.000519   \n",
       "2023-01-02                      0.000175              51.644680      0.000511   \n",
       "2023-01-03                      0.000162              51.644860      0.000499   \n",
       "2023-01-04                      0.000142              51.644740      0.000497   \n",
       "2023-01-05                      0.000139              51.644820      0.000490   \n",
       "\n",
       "            Mean Motion (revolutions per day)  \\\n",
       "Epoch                                           \n",
       "2023-01-01                          15.498221   \n",
       "2023-01-02                          15.498584   \n",
       "2023-01-03                          15.498874   \n",
       "2023-01-04                          15.499123   \n",
       "2023-01-05                          15.499368   \n",
       "\n",
       "            Revolution Number at Epoch_Diff  \\\n",
       "Epoch                                         \n",
       "2023-01-01                         9.166667   \n",
       "2023-01-02                        14.333333   \n",
       "2023-01-03                        15.200000   \n",
       "2023-01-04                        17.600000   \n",
       "2023-01-05                        13.800000   \n",
       "\n",
       "            Right Ascension of the Ascending Node (degrees)_sin  \\\n",
       "Epoch                                                             \n",
       "2023-01-01                                           0.961985     \n",
       "2023-01-02                                           0.937007     \n",
       "2023-01-03                                           0.904183     \n",
       "2023-01-04                                           0.857816     \n",
       "2023-01-05                                           0.816115     \n",
       "\n",
       "            Right Ascension of the Ascending Node (degrees)_cos  \\\n",
       "Epoch                                                             \n",
       "2023-01-01                                           0.273101     \n",
       "2023-01-02                                           0.349311     \n",
       "2023-01-03                                           0.427146     \n",
       "2023-01-04                                           0.513957     \n",
       "2023-01-05                                           0.577890     \n",
       "\n",
       "            Argument of Perigee (degrees)_sin  \\\n",
       "Epoch                                           \n",
       "2023-01-01                          -0.516587   \n",
       "2023-01-02                          -0.583451   \n",
       "2023-01-03                          -0.640969   \n",
       "2023-01-04                          -0.715327   \n",
       "2023-01-05                          -0.754367   \n",
       "\n",
       "            Argument of Perigee (degrees)_cos  Mean Anomaly (degrees)_sin  \\\n",
       "Epoch                                                                       \n",
       "2023-01-01                          -0.856235                   -0.991910   \n",
       "2023-01-02                          -0.812148                   -0.664510   \n",
       "2023-01-03                          -0.767566                   -0.384036   \n",
       "2023-01-04                          -0.698790                   -0.636479   \n",
       "2023-01-05                          -0.656453                   -0.944209   \n",
       "\n",
       "            Mean Anomaly (degrees)_cos  \n",
       "Epoch                                   \n",
       "2023-01-01                    0.126945  \n",
       "2023-01-02                   -0.747279  \n",
       "2023-01-03                   -0.923318  \n",
       "2023-01-04                   -0.771294  \n",
       "2023-01-05                   -0.329347  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_for_training[all_features].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "functional-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 2 # numbers of lags\n",
    "forecast_horizon = 1\n",
    "features = []\n",
    "targets = []\n",
    "num_samples = data_for_training.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "united-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (input features): (728, 22)\n",
      "Shape of y (target variables): (728, 11)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_samples - look_back - forecast_horizon + 1):\n",
    "    # The input features are the last `look_back` values of all series\n",
    "    X_window = data.iloc[i : i + look_back].values\n",
    "    \n",
    "    # The target variables are the next `forecast_horizon` values of all series\n",
    "    y_window = data.iloc[i + look_back : i + look_back + forecast_horizon].values\n",
    "    \n",
    "    # Flatten the windows to create a single row for the features and targets\n",
    "    features.append(X_window.flatten())\n",
    "    targets.append(y_window.flatten())\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(targets)\n",
    "\n",
    "print(f\"Shape of X (input features): {X.shape}\")\n",
    "print(f\"Shape of y (target variables): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bacterial-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((582, 22), (582, 11), (146, 22), (146, 11))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Scaling the Data ---\n",
    "# It's good practice to scale the data, especially for models that are\n",
    "# sensitive to feature magnitudes. We use a MinMaxScaler.\n",
    "# We need to scale X and y separately, and use a different scaler for each\n",
    "# to allow for inverse transformation later.\n",
    "\n",
    "# X_scaler = MinMaxScaler()\n",
    "# y_scaler = MinMaxScaler()\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "# --- 4. Splitting the Data ---\n",
    "# For time series, we split chronologically. The last 20% of the data\n",
    "# will be used for testing.\n",
    "split_index = int(len(X_scaled) * 0.8)\n",
    "X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n",
    "y_train, y_test = y_scaled[:split_index], y_scaled[split_index:]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-diabetes",
   "metadata": {},
   "source": [
    "# Traing classical ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "worth-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "SAVE_DIR = \"saved_model_state\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "models_and_params = [\n",
    "\n",
    "    {\n",
    "        'name': 'RandomForestRegressor',\n",
    "        'estimator': RandomForestRegressor(random_state=42, n_jobs=1), # Use n_jobs=1 for inner estimator\n",
    "        'param_grid': {\n",
    "            'estimator__n_estimators': [50, 100,],\n",
    "            'estimator__max_depth': [5, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    # 3. Linear/Robust Models\n",
    "    {\n",
    "        'name': 'RidgeRegressor',\n",
    "        'estimator': Ridge(random_state=42),\n",
    "        'param_grid': {\n",
    "            'estimator__alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'HuberRegressor',\n",
    "        'estimator': HuberRegressor(max_iter=1000), # Huber is robust to outliers\n",
    "        'param_grid': {\n",
    "            'estimator__epsilon': [1.1, 1.35]\n",
    "        }\n",
    "    },\n",
    "    # 4. Neighbors/SVM\n",
    "    {\n",
    "        'name': 'KNeighborsRegressor',\n",
    "        'estimator': KNeighborsRegressor(n_jobs=1),\n",
    "        'param_grid': {\n",
    "            'estimator__n_neighbors': [5, 10],\n",
    "            'estimator__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    # NOTE: SVR (Support Vector Regression) \n",
    "    {\n",
    "        'name': 'SVR',\n",
    "        'estimator': SVR(),\n",
    "        'param_grid': {\n",
    "            'estimator__C': [1.0, 10.0, 0.1, 100.0],\n",
    "            'estimator__kernel': ['rbf']\n",
    "        }\n",
    "    },\n",
    "    # 5. Simple Neural Network (MLP)\n",
    "    {\n",
    "        'name': 'MLPRegressor',\n",
    "        'estimator': MLPRegressor(random_state=42, max_iter=1000, early_stopping=True),\n",
    "        'param_grid': {\n",
    "            'estimator__hidden_layer_sizes': [(50,), (100,),],\n",
    "            'estimator__activation': ['relu', 'sigmoid']\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search CV for 6 Multi-Output Regressors...\n",
      "Models will be saved to: saved_model_state\n",
      "\n",
      "--- Training RandomForestRegressor ---\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "# --- Training and Saving Loop ---\n",
    "best_models = {}\n",
    "\n",
    "print(f\"Starting Grid Search CV for {len(models_and_params)} Multi-Output Regressors...\")\n",
    "print(f\"Models will be saved to: {SAVE_DIR}\")\n",
    "\n",
    "for item in models_and_params:\n",
    "    model_name = item['name']\n",
    "    base_estimator = item['estimator']\n",
    "    param_grid = item['param_grid']\n",
    "    \n",
    "    # 1. Wrap the estimator with MultiOutputRegressor\n",
    "    # n_jobs=-1 here parallelizes the training across the multiple output targets.\n",
    "    multi_output_model = MultiOutputRegressor(base_estimator, n_jobs=1)\n",
    "    \n",
    "    # 2. Configure GridSearchCV\n",
    "    # The 'estimator__' prefix targets the inner regressor's parameters.\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=multi_output_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=3,\n",
    "        verbose=1, # Reduced verbosity for a cleaner output with many models\n",
    "        n_jobs=1 # Parallelize the folds/hyperparameters across 1 core to avoid conflicts with MultiOutput's n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        # 3. Fit the model\n",
    "        # X_train and y_train are assumed to be defined and available\n",
    "        grid_search.fit(X_train, y_train) \n",
    "        \n",
    "        # 4. Save the best estimator\n",
    "        best_model = grid_search.best_estimator_\n",
    "        file_path = os.path.join(SAVE_DIR, f'best_{model_name}.joblib')\n",
    "        joblib.dump(best_model, file_path)\n",
    "        \n",
    "        best_models[model_name] = {\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'file_path': file_path\n",
    "        }\n",
    "        \n",
    "        print(f\"Finished {model_name}. Best score: {grid_search.best_score_:.4f}. Model saved to: {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Summary of Best Models ---\")\n",
    "for name, data in best_models.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"  Best Score (Neg MSE): {data['best_score']:.4f}\")\n",
    "    print(f\"  Best Params: {data['best_params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-metabolism",
   "metadata": {},
   "source": [
    "# Revert cyclical features and a differencing feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Prediction and Inverse Scaling ---\n",
    "# Make predictions on the test set. The predictions will be scaled.\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and the actual test data to their original scale\n",
    "y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Evaluation and Visualization ---\n",
    "# Reshape the data back into its original time series format for plotting and evaluation.\n",
    "# The shape is (num_test_samples, forecast_horizon * num_series).\n",
    "# We want to reshape it to (num_test_samples, forecast_horizon, num_series).\n",
    "y_test_reshaped = y_test_original.reshape(y_test_original.shape[0], forecast_horizon, -1)\n",
    "y_pred_reshaped = y_pred_original.reshape(y_pred_original.shape[0], forecast_horizon, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE and MAPE for each series over the entire test set\n",
    "mae_per_series = []\n",
    "mape_per_series = []\n",
    "rmse_per_series = []\n",
    "for i in range(y_test_reshaped.shape[2]):\n",
    "    actual_series = y_test_reshaped[:, :, i]\n",
    "    pred_series = y_pred_reshaped[:, :, i]\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(actual_series, pred_series)\n",
    "    mse = mean_squared_error(actual_series, pred_series)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse_per_series.append(rmse)\n",
    "    mae_per_series.append(mae)\n",
    "    \n",
    "    # Calculate a simple version of MAPE (Mean Absolute Percentage Error)\n",
    "    # We use a small epsilon to avoid division by zero.\n",
    "    # Note: MAPE is sensitive to zero or near-zero values.\n",
    "    non_zero_actuals = actual_series[np.abs(actual_series) > 1e-6]\n",
    "    if len(non_zero_actuals) > 0:\n",
    "        percentage_error = np.mean(np.abs((pred_series[np.abs(actual_series) > 1e-6] - non_zero_actuals) / non_zero_actuals)) * 100\n",
    "    else:\n",
    "        percentage_error = np.nan\n",
    "    mape_per_series.append(percentage_error)\n",
    "\n",
    "print(\"\\nMean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) for each time series:\")\n",
    "for i in range(len(mae_per_series)):\n",
    "#     print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}, MAPE = {mape_per_series[i]:.2f}%\")\n",
    "#     print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}\")\n",
    "    print(f\"  - Series {i+1} ({cols_for_training[i]}): RMSE = {rmse_per_series[i]:.4f} :MAE = {mae_per_series[i]:.9f}, MAPE = {mape_per_series[i]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions vs. actual values for the first time series\n",
    "\n",
    "for i in range(len(cols_for_training)):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.title(f\"Figure {i} {cols_for_training[i]}: Actual vs. Predicted (Test Set)\")\n",
    "    \n",
    "    if cols_for_training[i] == 'diff_revs_number':\n",
    "        plt.plot(y_test_reshaped[:, 0, i].cumsum(), label='Actual', color='blue')\n",
    "        plt.plot(y_pred_reshaped[:, 0, i].cumsum(), label='Predicted', color='red', linestyle='--')\n",
    "\n",
    "    else:\n",
    "        plt.plot(y_test_reshaped[:, 0, i], label='Actual', color='blue')\n",
    "        plt.plot(y_pred_reshaped[:, 0, i], label='Predicted', color='red', linestyle='--')\n",
    "        \n",
    "#     plt.plot(y_test_reshaped[:, 0, i], label='Actual', color='blue')\n",
    "#     plt.plot(y_pred_reshaped[:, 0, i], label='Predicted', color='red', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Test Sample\")\n",
    "    plt.ylabel(f\"{cols_for_training[i]} Value\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-experiment",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Model Training and Hyperparameter Tuning ---\n",
    "# We will now use GridSearchCV to find the best hyperparameters for multiple models.\n",
    "# The best model will be selected for evaluation.\n",
    "\n",
    "models = {\n",
    "    'RandomForestRegressor': {\n",
    "        'estimator': RandomForestRegressor(random_state=42),\n",
    "        'param_grid': {'estimator__n_estimators': [50, 100, 200], 'estimator__max_depth': [None, 5, 10]}\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'estimator': KNeighborsRegressor(),\n",
    "        'param_grid': {'estimator__n_neighbors': [3, 5, 7], 'estimator__weights': ['uniform', 'distance']}\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'estimator': GradientBoostingRegressor(random_state=42),\n",
    "        'param_grid': {'estimator__n_estimators': [50, 100], 'estimator__learning_rate': [0.05, 0.1]}\n",
    "    },\n",
    "    # SVR can be very slow, so we use a small, simple grid.\n",
    "    'SVR': {\n",
    "        'estimator': SVR(),\n",
    "        'param_grid': {'estimator__kernel': ['rbf'], 'estimator__C': [0.1, 1, 10]}\n",
    "    }\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = -np.inf\n",
    "best_model_name = \"\"\n",
    "\n",
    "print(\"\\nStarting Hyperparameter Tuning...\")\n",
    "\n",
    "for name, model_data in models.items():\n",
    "    print(f\"\\n--- Tuning {name} ---\")\n",
    "    base_estimator = model_data['estimator']\n",
    "    param_grid = model_data['param_grid']\n",
    "    \n",
    "    # Wrap the base estimator in MultiOutputRegressor\n",
    "    multi_output_estimator = MultiOutputRegressor(base_estimator, n_jobs=-1)\n",
    "    \n",
    "    # Set up GridSearchCV\n",
    "    grid_search = GridSearchCV(multi_output_estimator, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Finished tuning {name}\")\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score (negative MAE) for {name}: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Check if this is the best model so far\n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_score = grid_search.best_score_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\nModel tuning complete. The overall best model is: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'best_multi_output_model.joblib'\n",
    "save_path = 'MultiOutputModel'\n",
    "\n",
    "\n",
    "joblib.dump(best_model, os.path.join(save_path,model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Prediction and Inverse Scaling ---\n",
    "# Make predictions on the test set. The predictions will be scaled.\n",
    "y_pred_scaled = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and the actual test data to their original scale\n",
    "y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "y_test_reshaped = y_test_original.reshape(y_test_original.shape[0], forecast_horizon, -1)\n",
    "y_pred_reshaped = y_pred_original.reshape(y_pred_original.shape[0], forecast_horizon, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE and MAPE for each series over the entire test set\n",
    "mae_per_series = []\n",
    "mape_per_series = []\n",
    "for i in range(y_test_reshaped.shape[2]):\n",
    "    actual_series = y_test_reshaped[:, :, i]\n",
    "    pred_series = y_pred_reshaped[:, :, i]\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(actual_series, pred_series)\n",
    "    mae_per_series.append(mae)\n",
    "    \n",
    "    # Calculate a simple version of MAPE (Mean Absolute Percentage Error)\n",
    "    # We use a small epsilon to avoid division by zero.\n",
    "    # Note: MAPE is sensitive to zero or near-zero values.\n",
    "    non_zero_actuals = actual_series[np.abs(actual_series) > 1e-6]\n",
    "    if len(non_zero_actuals) > 0:\n",
    "        percentage_error = np.mean(np.abs((pred_series[np.abs(actual_series) > 1e-6] - non_zero_actuals) / non_zero_actuals)) * 100\n",
    "    else:\n",
    "        percentage_error = np.nan\n",
    "    mape_per_series.append(percentage_error)\n",
    "\n",
    "print(\"\\nMean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) for each time series:\")\n",
    "for i in range(len(mae_per_series)):\n",
    "#     print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}, MAPE = {mape_per_series[i]:.2f}%\")\n",
    "    print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-force",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-mlssa]",
   "language": "python",
   "name": "conda-env-conda-mlssa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
