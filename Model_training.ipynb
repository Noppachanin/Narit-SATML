{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the directory to sys.path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# Now you can import the module\n",
    "from utils.tle_processing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacetrack.operators as op\n",
    "from datetime import datetime,timedelta\n",
    "import pandas as pd\n",
    "from spacetrack import SpaceTrackClient\n",
    "from io import StringIO  # Import StringIO\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-senior",
   "metadata": {},
   "source": [
    "# Multi-output models\n",
    "- Vector Autoregression\n",
    "- RNN (TF)\n",
    "- MultiOutput Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_tle_df = pd.read_csv('sample_dataset/sample_TLE_40055.csv')\n",
    "resample_tle_df.set_index('Epoch', inplace=True)\n",
    "resample_tle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_tle_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Prepare Sample Data ---\n",
    "data_for_training = resample_tle_df.copy()\n",
    "\n",
    "# Add_diff\n",
    "# data_for_training['diff_eccentricity'] = data_for_training['Eccentricity'].diff()\n",
    "data_for_training['diff_revs_number'] =  data_for_training['Revolution Number at Epoch'].diff()\n",
    "data_for_training.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_for_training['First Derivative Mean Motion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_training = ['First Derivative Mean Motion', \n",
    "       'Mean Motion (revolutions per day)', \n",
    "       'Eccentricity',  'diff_revs_number', 'Inclination (degrees)',\n",
    "       'Right Ascension of the Ascending Node (degrees)',\n",
    "       'Argument of Perigee (degrees)', 'Mean Anomaly (degrees)']\n",
    "\n",
    "# Avoid near zero values \n",
    "# data_for_training['First Derivative Mean Motion'] = data_for_training['First Derivative Mean Motion']*10000\n",
    "# data_for_training['Eccentricity'] = data_for_training['Eccentricity']*10000\n",
    "\n",
    "\n",
    "\n",
    "data = data_for_training[cols_for_training].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-florence",
   "metadata": {},
   "source": [
    "## Statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "# ADF : unit root test ==> null hypothesis is non-stationary\n",
    "# Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Test ==> null hypothesis is stationary\n",
    "\n",
    "print('At confidence level 90%')\n",
    "\n",
    "for col in data.columns:\n",
    "    col_series = data[col]\n",
    "    \n",
    "    print(f\"Features : {col}\")\n",
    "    # Perform the ADF test\n",
    "    adf_result = adfuller(col_series)\n",
    "    #     print(\"ADF Statistic:\", adf_result[0])\n",
    "    #     print(\"p-value:\", adf_result[1])\n",
    "    #     print(\"Critical Values:\", adf_result[4])\n",
    "    \n",
    "    if adf_result[1] < 0.1:\n",
    "        print(f'p-value: {adf_result[1]} , Reject null for ADF: Stationary')\n",
    "    else:\n",
    "        print(f'p-value: {adf_result[1]} , Accept null for ADF: Non-stationary')\n",
    "        \n",
    "    # Perform the KPSS test\n",
    "    #     kpss_result = kpss(col_series)\n",
    "\n",
    "    #     if kpss_result[1] < 0.05:\n",
    "    #         print('Reject null for KPSS: Non-stationary')\n",
    "    #     else:\n",
    "    #         print('Accept null for KPSS: Stationary')\n",
    "    \n",
    "    print('=='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['Mean Anomaly (degrees)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation for Multi-Output Forecasting ---\n",
    "# We will create a dataset where the model predicts the next 1 time steps\n",
    "# using the previous 10 time steps.\n",
    "look_back = 2 # current + 2 records\n",
    "forecast_horizon = 1\n",
    "features = []\n",
    "targets = []\n",
    "num_samples = data_for_training.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples - look_back - forecast_horizon + 1):\n",
    "    # The input features are the last `look_back` values of all series\n",
    "    X_window = data.iloc[i : i + look_back].values\n",
    "    \n",
    "    # The target variables are the next `forecast_horizon` values of all series\n",
    "    y_window = data.iloc[i + look_back : i + look_back + forecast_horizon].values\n",
    "    \n",
    "    # Flatten the windows to create a single row for the features and targets\n",
    "    features.append(X_window.flatten())\n",
    "    targets.append(y_window.flatten())\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(targets)\n",
    "\n",
    "print(f\"Shape of X (input features): {X.shape}\")\n",
    "print(f\"Shape of y (target variables): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Scaling the Data ---\n",
    "# It's good practice to scale the data, especially for models that are\n",
    "# sensitive to feature magnitudes. We use a MinMaxScaler.\n",
    "# We need to scale X and y separately, and use a different scaler for each\n",
    "# to allow for inverse transformation later.\n",
    "\n",
    "# X_scaler = MinMaxScaler()\n",
    "# y_scaler = MinMaxScaler()\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "# --- 4. Splitting the Data ---\n",
    "# For time series, we split chronologically. The last 20% of the data\n",
    "# will be used for testing.\n",
    "split_index = int(len(X_scaled) * 0.8)\n",
    "X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n",
    "y_train, y_test = y_scaled[:split_index], y_scaled[split_index:]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Model Training ---\n",
    "# We instantiate a base estimator (RandomForestRegressor) and then wrap it\n",
    "# with the MultiOutputRegressor. This allows the model to predict all\n",
    "# output variables simultaneously.\n",
    "base_estimator = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model = MultiOutputRegressor(base_estimator, n_jobs=-1)\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "print(\"\\nTraining the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 6. Save the Trained Model ---\n",
    "# We'll save the model and the scalers so we can use them later without\n",
    "# retraining.\n",
    "model_filename = 'multi_output_model.joblib'\n",
    "\n",
    "\n",
    "\n",
    "# Your own path\n",
    "save_path = ''\n",
    "\n",
    "\n",
    "joblib.dump(model, os.path.join(save_path,model_filename))\n",
    "\n",
    "print(f\"\\nModel and scalers saved to {model_filename},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Prediction and Inverse Scaling ---\n",
    "# Make predictions on the test set. The predictions will be scaled.\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and the actual test data to their original scale\n",
    "y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Evaluation and Visualization ---\n",
    "# Reshape the data back into its original time series format for plotting and evaluation.\n",
    "# The shape is (num_test_samples, forecast_horizon * num_series).\n",
    "# We want to reshape it to (num_test_samples, forecast_horizon, num_series).\n",
    "y_test_reshaped = y_test_original.reshape(y_test_original.shape[0], forecast_horizon, -1)\n",
    "y_pred_reshaped = y_pred_original.reshape(y_pred_original.shape[0], forecast_horizon, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE and MAPE for each series over the entire test set\n",
    "mae_per_series = []\n",
    "mape_per_series = []\n",
    "rmse_per_series = []\n",
    "for i in range(y_test_reshaped.shape[2]):\n",
    "    actual_series = y_test_reshaped[:, :, i]\n",
    "    pred_series = y_pred_reshaped[:, :, i]\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(actual_series, pred_series)\n",
    "    mse = mean_squared_error(actual_series, pred_series)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse_per_series.append(rmse)\n",
    "    mae_per_series.append(mae)\n",
    "    \n",
    "    # Calculate a simple version of MAPE (Mean Absolute Percentage Error)\n",
    "    # We use a small epsilon to avoid division by zero.\n",
    "    # Note: MAPE is sensitive to zero or near-zero values.\n",
    "    non_zero_actuals = actual_series[np.abs(actual_series) > 1e-6]\n",
    "    if len(non_zero_actuals) > 0:\n",
    "        percentage_error = np.mean(np.abs((pred_series[np.abs(actual_series) > 1e-6] - non_zero_actuals) / non_zero_actuals)) * 100\n",
    "    else:\n",
    "        percentage_error = np.nan\n",
    "    mape_per_series.append(percentage_error)\n",
    "\n",
    "print(\"\\nMean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) for each time series:\")\n",
    "for i in range(len(mae_per_series)):\n",
    "#     print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}, MAPE = {mape_per_series[i]:.2f}%\")\n",
    "#     print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}\")\n",
    "    print(f\"  - Series {i+1} ({cols_for_training[i]}): RMSE = {rmse_per_series[i]:.4f} :MAE = {mae_per_series[i]:.9f}, MAPE = {mape_per_series[i]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions vs. actual values for the first time series\n",
    "\n",
    "for i in range(len(cols_for_training)):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.title(f\"Figure {i} {cols_for_training[i]}: Actual vs. Predicted (Test Set)\")\n",
    "    \n",
    "    if cols_for_training[i] == 'diff_revs_number':\n",
    "        plt.plot(y_test_reshaped[:, 0, i].cumsum(), label='Actual', color='blue')\n",
    "        plt.plot(y_pred_reshaped[:, 0, i].cumsum(), label='Predicted', color='red', linestyle='--')\n",
    "\n",
    "    else:\n",
    "        plt.plot(y_test_reshaped[:, 0, i], label='Actual', color='blue')\n",
    "        plt.plot(y_pred_reshaped[:, 0, i], label='Predicted', color='red', linestyle='--')\n",
    "        \n",
    "#     plt.plot(y_test_reshaped[:, 0, i], label='Actual', color='blue')\n",
    "#     plt.plot(y_pred_reshaped[:, 0, i], label='Predicted', color='red', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Test Sample\")\n",
    "    plt.ylabel(f\"{cols_for_training[i]} Value\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-comparative",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Model Training and Hyperparameter Tuning ---\n",
    "# We will now use GridSearchCV to find the best hyperparameters for multiple models.\n",
    "# The best model will be selected for evaluation.\n",
    "\n",
    "models = {\n",
    "    'RandomForestRegressor': {\n",
    "        'estimator': RandomForestRegressor(random_state=42),\n",
    "        'param_grid': {'estimator__n_estimators': [50, 100, 200], 'estimator__max_depth': [None, 5, 10]}\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'estimator': KNeighborsRegressor(),\n",
    "        'param_grid': {'estimator__n_neighbors': [3, 5, 7], 'estimator__weights': ['uniform', 'distance']}\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'estimator': GradientBoostingRegressor(random_state=42),\n",
    "        'param_grid': {'estimator__n_estimators': [50, 100], 'estimator__learning_rate': [0.05, 0.1]}\n",
    "    },\n",
    "    # SVR can be very slow, so we use a small, simple grid.\n",
    "    'SVR': {\n",
    "        'estimator': SVR(),\n",
    "        'param_grid': {'estimator__kernel': ['rbf'], 'estimator__C': [0.1, 1, 10]}\n",
    "    }\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = -np.inf\n",
    "best_model_name = \"\"\n",
    "\n",
    "print(\"\\nStarting Hyperparameter Tuning...\")\n",
    "\n",
    "for name, model_data in models.items():\n",
    "    print(f\"\\n--- Tuning {name} ---\")\n",
    "    base_estimator = model_data['estimator']\n",
    "    param_grid = model_data['param_grid']\n",
    "    \n",
    "    # Wrap the base estimator in MultiOutputRegressor\n",
    "    multi_output_estimator = MultiOutputRegressor(base_estimator, n_jobs=-1)\n",
    "    \n",
    "    # Set up GridSearchCV\n",
    "    grid_search = GridSearchCV(multi_output_estimator, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Finished tuning {name}\")\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score (negative MAE) for {name}: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Check if this is the best model so far\n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_score = grid_search.best_score_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\nModel tuning complete. The overall best model is: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'best_multi_output_model.joblib'\n",
    "save_path = 'MultiOutputModel'\n",
    "\n",
    "\n",
    "joblib.dump(best_model, os.path.join(save_path,model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Prediction and Inverse Scaling ---\n",
    "# Make predictions on the test set. The predictions will be scaled.\n",
    "y_pred_scaled = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and the actual test data to their original scale\n",
    "y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "y_test_reshaped = y_test_original.reshape(y_test_original.shape[0], forecast_horizon, -1)\n",
    "y_pred_reshaped = y_pred_original.reshape(y_pred_original.shape[0], forecast_horizon, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE and MAPE for each series over the entire test set\n",
    "mae_per_series = []\n",
    "mape_per_series = []\n",
    "for i in range(y_test_reshaped.shape[2]):\n",
    "    actual_series = y_test_reshaped[:, :, i]\n",
    "    pred_series = y_pred_reshaped[:, :, i]\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(actual_series, pred_series)\n",
    "    mae_per_series.append(mae)\n",
    "    \n",
    "    # Calculate a simple version of MAPE (Mean Absolute Percentage Error)\n",
    "    # We use a small epsilon to avoid division by zero.\n",
    "    # Note: MAPE is sensitive to zero or near-zero values.\n",
    "    non_zero_actuals = actual_series[np.abs(actual_series) > 1e-6]\n",
    "    if len(non_zero_actuals) > 0:\n",
    "        percentage_error = np.mean(np.abs((pred_series[np.abs(actual_series) > 1e-6] - non_zero_actuals) / non_zero_actuals)) * 100\n",
    "    else:\n",
    "        percentage_error = np.nan\n",
    "    mape_per_series.append(percentage_error)\n",
    "\n",
    "print(\"\\nMean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) for each time series:\")\n",
    "for i in range(len(mae_per_series)):\n",
    "#     print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}, MAPE = {mape_per_series[i]:.2f}%\")\n",
    "    print(f\"  - Series {i+1} ({cols_for_training[i]}): MAE = {mae_per_series[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-mlssa]",
   "language": "python",
   "name": "conda-env-conda-mlssa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
